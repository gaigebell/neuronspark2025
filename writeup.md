# Guess&Guess Writeup

member: zhongqijun

device: 

- CPU: 1 × Intel(R) Core(TM) i9-14900HX
- GPU: 1 × NVIDIA GeForce RTX 4060 Laptop GPU

---

### 00 须弥识花大赛

- 直接对 pytorch 中的 resnet18 进行微调， resnet18 全连接层输出数改为 18 （18 个标签），最后经过 Softmax

- 数据处理： 
    - 训练集随机裁切 $384\times 384$，随机水平翻转，按 ImageNet 统计信息归一化
    - 测试集中心裁切 $384\times 384$, 按 ImageNet 统计信息归一化
    - 训练集划分：80% 数据用于训练，20% 数据用于验证，且按照标签比例划分，保证训练集和验证集中标签比例相同

- 训练细节：
    - 批大小: 32
    - 损失函数: 交叉熵
    - 优化器：Adam, 学习率 $10^{-4}$
    - 训练轮次：65

---

### 01 消影行动：去水印特工

没时间写了，直接交了原图...

---

### 02 CLEAN I

直接微调现有的大模型:)

微调 Qwen2.5-0.5B-Instruct

用 HuggingFace 的 PEFT, 微调 Qwen2.5-0.5B-Instruct 的分类模型，标签数改为 2 

显存不够，只选取了 8% 的数据进行训练，其中 85% 划分为训练集， 15% 划分为验证集

LoRA 方法 + 提示词调优

提示词：
> 【任务说明】
> 
> 你是一个专业的网络内容审核助手,结合下列手册和你的专业素养,判断后面给出的网络评论是否包含辱骂、歧视、仇恨等情绪,正常评论输出0,负面评论输出1
>
> 【手册】
> 
> 1. 后面给出的网络评论格式为微博评论格式,形如:当前用户评论内容//@其他用户A:A的评论内容//@其他用户B:B的评论内容...
> 2. 请结合其他用户评论内容作为上文来帮助你判断当前用户评论内容是否违规
> 3. 评论中包含表情包，格式为[表情内容]，如：[泪]
> 4. 请注意分辨反讽、玩笑、报道等容易混淆的内容
> 
> 【待判断网络评论】: {text}
> 
>  答案(0/1)：

超参数：
- 学习率 $3\times 10^{-5}$
- 批大小: 8
- 训练轮次: 2


---


### 04 冷启动之劫如何破？

直接给所有用户推荐 Top10 热门电影

---

### 06 Key-DeepSeek-v3

暴力

枚举所有可能性，不会很大，每个数字在 10w 以内，以时间换分数

---

### 07 LLM to BTs

直接调用 Qwen2.5-1.5B-Instruct ，配合提示词

提示词：

> 你是一个将自然语言指令转换为XML格式行为树的专家，下面给一段英文自然语言指令，请你
> 1. **仔细分析、识别并理解**指令中的所有逻辑和功能
> 2. 然后**一一实现**指令中的所有逻辑和功能
> 3. 生成对应结构化的XML格式行为树
>
> 自然语言指令：{text}

---

###  08 我搭的靶场

尽可能延缓，消耗其步数


策略偏好：右，上，左，下

#### 奖励


比先前近了
$$
r_1 = \dfrac{15}{d_{\rm goal} +1}
$$
比先前远了
$$
r_2 = \dfrac{5}{d_{\rm goal} +1}
$$

#### 惩罚

靠近障碍
$$
r_3 = \sum_i \dfrac{5}{d_{\rm ob} + 1}
$$
回到以前的点
$$
r_4 = 2
$$

强化学习中，有一种常见的 agent 没有像预期中学习的情况，就是逃避惩罚. 当得不到奖励的时候，agent 就会陷入逃避惩罚的局部最优解.

在这里，比如 $r_3 > r_1 + r_2$ 的时候，就会诱导 agent 减少 $r_3$ 即远离可见的障碍物.

那么一种朴素的想法就是在终点附近布置高密度的障碍，诱导 agent 远离终点，消耗训练步数.

---

### 10 帧帧皆玄机

直接调用 OpenAI 的 clip-vit-base-patch32 （用不了更好的模型了，硬件跟不上）

选择 $P(选项|视频)$ 最大的一个选项.

